# ğŸš€ EfficientNet-B0 vs. B1 Comparison on CIFAR-100

![PyTorch](https://img.shields.io/badge/Framework-PyTorch-red?logo=pytorch)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen)
![License](https://img.shields.io/badge/License-MIT-blue)
![Stars](https://img.shields.io/github/stars/shivanshu2109/EfficientNet-B0-vs-B1-Comparison?style=social)

> ğŸ“Š Compare training speed, accuracy, and generalization between two EfficientNet-Lite architectures built from scratch in **PyTorch**!

---

## ğŸ§  Project Overview

This project implements and compares **EfficientNet-Lite B0 and a mini B1** variant on the **CIFAR-100** dataset using PyTorch.  
We build the models **from scratch** to understand performance trade-offs across:

- ğŸƒ Training speed  
- ğŸ¯ Validation accuracy  
- ğŸ” Generalization over 100 epochs

---

## âœ¨ Key Features

- ğŸ”§ **EfficientNet-Lite Implementation** â€“ Custom modules built using PyTorch.
- ğŸ§± **MBConv Blocks** â€“ Includes depthwise/pointwise convolutions, SE blocks, and skip connections.
- ğŸŒŠ **Custom Swish Activation** â€“ Implemented as: `x * sigmoid(x)`
- ğŸ–¼ï¸ **CIFAR-100 Dataset** â€“ Automatically downloaded and preprocessed.
- ğŸ“Š **Side-by-Side Comparison** â€“ Visual & quantitative comparison between B0 and mini B1.

---

### ğŸ” Model Comparison

We trained two custom EfficientNet variants:
- **B0-like Model** (Baseline)
- **Mini B1 Model** (Deeper, more complex)

| Model       | Final Val Accuracy | Best Val Accuracy | Comments |
|-------------|--------------------|-------------------|----------|
| B0-like     | 34.37%             | âœ… Best performance | Stable learning |
| Mini B1     | 24.14%             | âŒ Lower accuracy  | Early overfitting |

ğŸ“Œ _Conclusion:_ The B0-like model generalizes better and is preferred for deployment or further improvement.
all torch torchvision matplotlib scikit-learn seaborn numpy
